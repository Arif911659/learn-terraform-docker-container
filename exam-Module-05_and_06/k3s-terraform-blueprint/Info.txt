aws_instance.k3s_worker[0]: Creation complete after 12s [id=i-00c2c6f39f17296e3]
aws_instance.k3s_worker[1]: Creation complete after 13s [id=i-0ed440ca88bbbf847]
aws_instance.nginx: Creation complete after 13s [id=i-03ad0e29d3c0c3efd]

Outputs:

keypair_location = "./k3s-key-pair.pem"
master_node_private_ip = "10.0.2.114"
nginx_private_ip = "10.0.1.82"
nginx_public_ip = "47.129.186.77"
worker_node_private_ip = [
  "10.0.2.60",
  "10.0.2.177",
]






=========================
k3s-terraform-blueprint/
├── main.tf
├── providers.tf
├── variables.tf
├── outputs.tf
├── modules/
│   ├── network/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   ├── compute/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   └── load_balancer/
│       ├── main.tf
│       ├── variables.tf
│       └── outputs.tf


1. Network Module
The network module will handle VPC, public and private subnets, and routing.

modules/network/main.tf

resource "aws_vpc" "main" {
  cidr_block = var.vpc_cidr
}

resource "aws_subnet" "public" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = var.public_subnet_cidr
  map_public_ip_on_launch = true
}

resource "aws_subnet" "private" {
  vpc_id     = aws_vpc.main.id
  cidr_block = var.private_subnet_cidr
}

resource "aws_internet_gateway" "gw" {
  vpc_id = aws_vpc.main.id
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.gw.id
  }
}

resource "aws_route_table_association" "public" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public.id
}

output "vpc_id" {
  value = aws_vpc.main.id
}

output "public_subnet_id" {
  value = aws_subnet.public.id
}

output "private_subnet_id" {
  value = aws_subnet.private.id
}
modules/network/variables.tf

variable "vpc_cidr" {
  type        = string
  description = "CIDR block for VPC"
}

variable "public_subnet_cidr" {
  type        = string
  description = "CIDR block for public subnet"
}

variable "private_subnet_cidr" {
  type        = string
  description = "CIDR block for private subnet"
}
2. Compute Module
The compute module will create EC2 instances for the k3s master and worker nodes in the private subnet.

modules/compute/main.tf

resource "aws_instance" "k3s_master" {
  ami           = var.ami
  instance_type = var.instance_type
  subnet_id     = var.private_subnet_id
  key_name      = var.key_name

  tags = {
    Name = "k3s-master"
  }
}

resource "aws_instance" "k3s_worker" {
  count         = var.worker_count
  ami           = var.ami
  instance_type = var.instance_type
  subnet_id     = var.private_subnet_id
  key_name      = var.key_name

  tags = {
    Name = "k3s-worker-${count.index + 1}"
  }
}

output "k3s_master_private_ip" {
  value = aws_instance.k3s_master.private_ip
}

output "k3s_worker_private_ips" {
  value = [for instance in aws_instance.k3s_worker : instance.private_ip]
}
modules/compute/variables.tf

variable "ami" {
  type        = string
  description = "AMI for EC2 instances"
}

variable "instance_type" {
  type        = string
  description = "Instance type for k3s nodes"
}

variable "private_subnet_id" {
  type        = string
  description = "Private subnet ID"
}

variable "key_name" {
  type        = string
  description = "Key pair name for EC2 instances"
}

variable "worker_count" {
  type        = number
  default     = 2
  description = "Number of worker nodes"
}
3. Load Balancer Module
This module will set up an Nginx server as a load balancer in the public subnet, routing requests to the private subnet.

modules/load_balancer/main.tf

resource "aws_instance" "nginx_lb" {
  ami           = var.ami
  instance_type = var.instance_type
  subnet_id     = var.public_subnet_id
  key_name      = var.key_name

  user_data = <<-EOF
              #!/bin/bash
              apt update -y
              apt install nginx -y
              echo "upstream k3s_nodes {" >> /etc/nginx/nginx.conf
              EOF

  tags = {
    Name = "nginx-lb"
  }
}

output "lb_public_ip" {
  value = aws_instance.nginx_lb.public_ip
}
modules/load_balancer/variables.tf

variable "ami" {
  type        = string
  description = "AMI for Nginx load balancer"
}

variable "instance_type" {
  type        = string
  description = "Instance type for Nginx load balancer"
}

variable "public_subnet_id" {
  type        = string
  description = "Public subnet ID"
}

variable "key_name" {
  type        = string
  description = "Key pair name for EC2 instances"
}
4. Main Configuration
The main.tf file ties together all modules and specifies values for the variables.

main.tf

module "network" {
  source             = "./modules/network"
  vpc_cidr           = "10.0.0.0/16"
  public_subnet_cidr = "10.0.1.0/24"
  private_subnet_cidr = "10.0.2.0/24"
}

module "compute" {
  source             = "./modules/compute"
  ami                = "ami-0c55b159cbfafe1f0" # Example Ubuntu AMI
  instance_type      = "t2.micro"
  private_subnet_id  = module.network.private_subnet_id
  key_name           = var.key_name
  worker_count       = 2
}

module "load_balancer" {
  source             = "./modules/load_balancer"
  ami                = "ami-0c55b159cbfafe1f0" # Example Ubuntu AMI for Nginx
  instance_type      = "t2.micro"
  public_subnet_id   = module.network.public_subnet_id
  key_name           = var.key_name
}

output "lb_public_ip" {
  value = module.load_balancer.lb_public_ip
}
5. Variables and Outputs
Add a variables.tf file for common variables, including key_name for the EC2 key pair.

variables.tf

variable "key_name" {
  type        = string
  description = "Key pair for SSH access to EC2 instances"
}
This setup will create a k3s cluster in a private subnet and an Nginx load balancer in a public subnet. You can further configure the Nginx server to forward traffic to the k3s nodes once you install k3s on the EC2 instances. Let me know if you need any additional guidance!


apiVersion: apps/v1
kind: Deployment
metadata:
  name: flask-api
  labels:
    app: flask-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: flask-api
  template:
    metadata:
      labels:
        app: flask-api
    spec:
      containers:
      - name: flask-api
        image: arifhossaincse22/flask-api:latest
        ports:
        - containerPort: 5000
---
# Flask API service
apiVersion: v1
kind: Service
metadata:
  name: flask-api
  namespace: default
spec:
  type: NodePort
  selector:
    app: flask-api
  ports:
    - port: 5000
      targetPort: 5000
      nodePort: 30001



2. React App Deployment and Service
react-deployment.yaml


ubuntu@master:~$ cat react-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: react-app
  labels:
    app: react-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: react-app
  template:
    metadata:
      labels:
        app: react-app
    spec:
      containers:
      - name: react-app
        image: arifhossaincse22/react-app:latest
        ports:
        - containerPort: 3000
---
# React app service
apiVersion: v1
kind: Service
metadata:
  name: react-app
  namespace: default
spec:
  type: NodePort
  selector:
    app: react-app
  ports:
    - port: 3000
      targetPort: 3000
      nodePort: 30002



===============================

ubuntu@nginx-lb:~$ cat /etc/nginx/nginx.conf
events {
                  worker_connections 1024;
              }

              http {
                  upstream react_app {
                      least_conn;
                      server 10.0.2.114:30002 max_fails=3 fail_timeout=30s;
                      server 10.0.2.60:30002 max_fails=3 fail_timeout=30s;
                      server 10.0.2.177:30002 max_fails=3 fail_timeout=30s;
                  }

                  upstream flask_api {
                      least_conn;
                      server 10.0.2.114:30001 max_fails=3 fail_timeout=30s;
                      server 10.0.2.60:30001 max_fails=3 fail_timeout=30s;
                      server 10.0.2.177:30001 max_fails=3 fail_timeout=30s;
                  }

                  server {
                      listen 80;
                      server_name _;

                      # Health check endpoint
                      location /health {
                          return 200 'healthy\n';
                          add_header Content-Type text/plain;
                      }

                      location / {
                          proxy_pass http://react_app;
                          proxy_http_version 1.1;
                          proxy_set_header Host \$host;
                          proxy_set_header X-Real-IP \$remote_addr;
                          proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for                                ;
                          proxy_set_header X-Forwarded-Proto \$scheme;

                          # Timeouts
                          proxy_connect_timeout 60s;
                          proxy_send_timeout 60s;
                          proxy_read_timeout 60s;
                      }

                      location /api/ {
                          proxy_pass http://flask_api;
                          proxy_http_version 1.1;
                          proxy_set_header Host \$host;
                          proxy_set_header X-Real-IP \$remote_addr;
                          proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for                                ;
                          proxy_set_header X-Forwarded-Proto \$scheme;

                          # Timeouts
                          proxy_connect_timeout 60s;
                          proxy_send_timeout 60s;
                          proxy_read_timeout 60s;
                      }
                  }
              }
===>>>
1. Check Nginx User Permissions
Ensure that Nginx has the correct permissions for the /run/ directory. You can adjust the permissions with:


sudo chown -R www-data:www-data /run/nginx.pid

2. Restart Nginx with Elevated Permissions
Try restarting Nginx with sudo to ensure it has the necessary permissions:


sudo systemctl restart nginx

3. Verify and Update nginx.conf Permissions
Confirm that the nginx.conf file and its directories are owned by root or the Nginx user:


sudo chown root:root /etc/nginx/nginx.conf

4. Check for Open Nginx Processes
Sometimes an existing Nginx process might be preventing changes. Stop any running Nginx processes, and restart:


sudo pkill nginx
sudo systemctl start nginx

5. Test Nginx Configuration
Finally, re-test your Nginx configuration to confirm no further syntax or permission issues:


sudo nginx -t